# ğŸ’¬ Gemini Chat Assistant

A lightweight conversational AI app built using **LangChain** and **Streamlit**, powered by **Google's Gemini 2.5 Flash** model.  
This project turns your terminal-based conversation into a sleek, memory-enabled **ChatGPT-style web interface**.

---

## ğŸš€ Features

âœ… Real-time AI chat using Gemini 2.5 Flash  
âœ… Conversational memory (multi-turn context)  
âœ… Modern Streamlit UI with chat bubbles  
âœ… Minimal setup â€” just plug in your API key and run  
âœ… Extensible design for custom system roles, themes, or data sources

---

## ğŸ§© Tech Stack

- **Python 3.10+**
- **Streamlit** â€“ UI layer  
- **LangChain** â€“ model orchestration  
- **Google Generative AI (Gemini)** â€“ large language model  
- **dotenv** â€“ for environment variable management

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/your-username/gemini-chat-assistant.git
cd gemini-chat-assistant
```
### 2ï¸âƒ£ Create a virtual environment (recommended)

```python -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scripts\activate      # On Windows
```

### 3ï¸âƒ£ Install dependencies

```bash 
pip install -r requirements.txt
```

If you donâ€™t have a requirements.txt yet, hereâ€™s what it should contain:

streamlit
python-dotenv
langchain-google-genai
langchain-core

### ğŸ”‘ API Key Setup

Go to your Google AI Studio
Generate a Gemini API key
Create a .env file in your project root and add:

```bash
GEMINI_API_KEY=your_actual_api_key_here
```
ğŸ§  How to Run
```bash
streamlit run app.py
```

Then open the URL shown in your terminal - usually:
```bash
http://localhost:8501
```

ğŸ’¬ Usage

Type your message in the input box
The assistant replies instantly
It remembers previous messages within the session